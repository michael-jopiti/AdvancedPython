{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Week 6 - Assignment</center></h2>\n",
    "<h3><center>Programming for Data Science 2024</center></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises for the topics covered in the sixth lecture.\n",
    "\n",
    "The exercise will be marked as passed if you get **at least 10/15** points.\n",
    "\n",
    "Exercises must be handed in via **ILIAS** (Homework assignments). Deliver your submission as a compressed file (zip) containing one .py or .ipynb file with all exercises. The name of both the .zip and the .py/.ipynb file **must** be *SurnameName* of the two members of the group. Example: Riccardo Cusinato + Athina Tzovara = *CusinatoRiccardo_TzovaraAthina.zip* .\n",
    "\n",
    "It's important to use comments to explain your code and show that you're able to take ownership of the exercises and discuss them.\n",
    "\n",
    "You are not expected to collaborate outside of the group on exercises and submitting other groups’ code as your own will result in 0 points.\n",
    "\n",
    "For questions contact: *riccardo.cusinato@unibe.ch* with the subject: *Programming for Data Science 2024*.\n",
    "\n",
    "**Deadline: 14:00, April 11, 2024.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 1 - World Happiness Report<span style=\"float: right\">8 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find the CSV files *report.csv* and *region.csv* in the data folder for this assignment (Credit: https://www.kaggle.com/ajaypalsinghlo/world-happiness-report-2021).\n",
    "\n",
    "1. Import the two *csv* files and save them in two variables called *df_report* and *df_region*. Create a new column \"region\" in the *df_report* dataframe by populating it with the correct region in the *df_region* dataframe. If a country does not exist in *df_region*, label it as \"unknown\" in *df_report*. Print *df_report* at the end. (*2 points*)\n",
    "\n",
    "**NB** If you are unable to do the exercise, you can use the file *report_region.csv* in the data folder for the next points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Calculate and print the median \"Healthy life expectancy at birth\" per region in the year 2019. (*2 point*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a Pivot table with the median \"Healthy life expectancy at birth\" per region (index) per year (column) and print it. (*1 point*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a Pivot table (same structure as before) with the maximum \"Log GDP per capita\" per region per year and print it. In the resulting table, also add the overall values across years for each region, with the appropriate pandas method. (*1 point*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Find the length of the shortest country name(s) in the dataset and print it, together with the actual countries (print just the unique occurrences!). Then, create a new column ”Short name”, where each country name is cut down to the length of the shortest country name. For instance, if the country with the shortest name is Germany (7 letters, and not true, just an example), ”Switzerland” would become ”Switzer”. (*2 points*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "# YOUR CODE HERE\n",
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:left;\">Exercise 2 - Weather data<span style=\"float: right\">7 points</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you'll use the *weather.csv* dataset that contains UK weather data. The dataset has columns year and month describing which year and month a specific recording belongs to. (Credit: https://www.kaggle.com/josephw20/uk-met-office-weather-data)\n",
    "\n",
    "1. Import the dataset into a dataframe called *df_weather* and create a new column *datetime*, containing a datetime object for each row describing the year and month of the recording. The day can be set as the 1st of the month. Finally, print the dataframe. (*2 points*)\n",
    "\n",
    "**NB**  If you are unable to do this exercise, you can use the file *weather_datetime.csv* in the data folder for the next points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(df_weather['month'].isnull()))\n",
    "print(np.sum(df_weather['year'].isnull()))\n",
    "\n",
    "# We have 20 missing data in each of these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot convert NA to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m df_weather[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_weather[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInt64\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m df_weather[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;66;03m# create a new column for the first day of the month\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m df_weather[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df_weather[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m]], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m df_weather[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_weather[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_weather)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1053\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1051\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39m_constructor(values, index\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mindex, name\u001b[38;5;241m=\u001b[39marg\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (ABCDataFrame, abc\u001b[38;5;241m.\u001b[39mMutableMapping)):\n\u001b[0;32m-> 1053\u001b[0m     result \u001b[38;5;241m=\u001b[39m _assemble_from_unit_mappings(arg, errors, utc)\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, Index):\n\u001b[1;32m   1055\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m _maybe_cache(arg, \u001b[38;5;28mformat\u001b[39m, cache, convert_listlike)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1192\u001b[0m, in \u001b[0;36m_assemble_from_unit_mappings\u001b[0;34m(arg, errors, utc)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m   1191\u001b[0m values \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1192\u001b[0m     coerce(arg[unit_rev[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m\"\u001b[39m]]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m   1193\u001b[0m     \u001b[38;5;241m+\u001b[39m coerce(arg[unit_rev[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m\"\u001b[39m]]) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m   1194\u001b[0m     \u001b[38;5;241m+\u001b[39m coerce(arg[unit_rev[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m]])\n\u001b[1;32m   1195\u001b[0m )\n\u001b[1;32m   1196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1197\u001b[0m     values \u001b[38;5;241m=\u001b[39m to_datetime(values, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, errors\u001b[38;5;241m=\u001b[39merrors, utc\u001b[38;5;241m=\u001b[39mutc)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/tools/datetimes.py:1188\u001b[0m, in \u001b[0;36m_assemble_from_unit_mappings.<locals>.coerce\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[38;5;66;03m# prevent overflow in case of int8 or int16\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(values):\n\u001b[0;32m-> 1188\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m\"\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:6324\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6317\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6318\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[:, i]\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m   6319\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns))\n\u001b[1;32m   6320\u001b[0m     ]\n\u001b[1;32m   6322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6323\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6324\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   6325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_data)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6327\u001b[0m \u001b[38;5;66;03m# GH 33113: handle empty frame or series\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:451\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    449\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    453\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    454\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    455\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    456\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[1;32m    457\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:352\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    351\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 352\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    355\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:511\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[38;5;124;03mCoerce to the new dtype.\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03mBlock\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    509\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n\u001b[0;32m--> 511\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m    513\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    515\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:242\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    239\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 242\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/dtypes/astype.py:184\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;66;03m# i.e. ExtensionArray\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:498\u001b[0m, in \u001b[0;36mBaseMaskedArray.astype\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;66;03m# to_numpy will also raise, but we get somewhat nicer exception messages here\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hasna:\n\u001b[0;32m--> 498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert NA to integer\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bool_dtype(dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_hasna:\n\u001b[1;32m    500\u001b[0m     \u001b[38;5;66;03m# careful: astype_nansafe converts np.nan to True\u001b[39;00m\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert float NaN to bool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot convert NA to integer"
     ]
    }
   ],
   "source": [
    "df_weather = pd.read_csv('./dataW6/weather.csv')\n",
    "\n",
    "\n",
    "df_weather['month'] = df_weather['month'].astype('Int64') # convert to int values, NA like values are replace by pandas.NA\n",
    "df_weather['year'] = df_weather['year'].astype('Int64')\n",
    "df_weather['day'] = 1 # create a new column for the first day of the month\n",
    "\n",
    "df_weather['datetime'] = pd.to_datetime(df_weather[['year', 'month', 'day']], errors='ignore')\n",
    "\n",
    "df_weather['datetime'] = df_weather['datetime'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "\n",
    "print(df_weather)\n",
    "print(df_weather[df_weather['month'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         year  month  tmax  tmin   af   rain    sun    station  day   datetime\n",
      "0      1941.0    1.0   NaN   NaN  NaN   74.7    NaN  aberporth    1 1941-01-01\n",
      "1      1941.0    2.0   NaN   NaN  NaN   69.1    NaN  aberporth    1 1941-02-01\n",
      "2      1941.0    3.0   NaN   NaN  NaN   76.2    NaN  aberporth    1 1941-03-01\n",
      "3      1941.0    4.0   NaN   NaN  NaN   33.7    NaN  aberporth    1 1941-04-01\n",
      "4      1941.0    5.0   NaN   NaN  NaN   51.3    NaN  aberporth    1 1941-05-01\n",
      "...       ...    ...   ...   ...  ...    ...    ...        ...  ...        ...\n",
      "37044  2020.0    2.0  10.8   4.5  2.0  117.4   63.1  yeovilton    1 2020-02-01\n",
      "37045  2020.0    3.0  11.5   3.0  6.0   43.4  159.2  yeovilton    1 2020-03-01\n",
      "37046  2020.0    4.0  17.5   5.3  3.0   39.8  235.0  yeovilton    1 2020-04-01\n",
      "37047  2020.0    5.0  19.7   6.8  2.0    3.6  305.6  yeovilton    1 2020-05-01\n",
      "37048  2020.0    6.0  20.5  11.0  0.0  103.0  187.6  yeovilton    1 2020-06-01\n",
      "\n",
      "[37049 rows x 10 columns]\n",
      "       year  month  tmax  tmin  af  rain  sun       station  day datetime\n",
      "3540    NaN    NaN   NaN   NaN NaN   NaN  NaN  ballypatrick    1      NaT\n",
      "5023    NaN    NaN   NaN   NaN NaN   NaN  NaN       braemar    1      NaT\n",
      "8908    NaN    NaN   NaN   NaN NaN   NaN  NaN    cwmystwyth    1      NaT\n",
      "9366    NaN    NaN   NaN   NaN NaN   NaN  NaN  dunstaffnage    1      NaT\n",
      "16706   NaN    NaN   NaN   NaN NaN   NaN  NaN     lowestoft    1      NaT\n",
      "17820   NaN    NaN   NaN   NaN NaN   NaN  NaN     lowestoft    1      NaT\n",
      "18745   NaN    NaN   NaN   NaN NaN   NaN  NaN       manston    1      NaT\n",
      "18923   NaN    NaN   NaN   NaN NaN   NaN  NaN         nairn    1      NaT\n",
      "19734   NaN    NaN   NaN   NaN NaN   NaN  NaN         nairn    1      NaT\n",
      "24191   NaN    NaN   NaN   NaN NaN   NaN  NaN       ringway    1      NaT\n",
      "27811   NaN    NaN   NaN   NaN NaN   NaN  NaN   southampton    1      NaT\n",
      "29555   NaN    NaN   NaN   NaN NaN   NaN  NaN   southampton    1      NaT\n",
      "34387   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1      NaT\n",
      "34633   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1      NaT\n",
      "34795   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1      NaT\n",
      "34797   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1      NaT\n",
      "34799   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1      NaT\n",
      "34801   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1      NaT\n",
      "34803   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1      NaT\n",
      "34855   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1      NaT\n"
     ]
    }
   ],
   "source": [
    "# Load the weather data\n",
    "df_weather = pd.read_csv('./dataW6/weather.csv')\n",
    "\n",
    "# Convert \"month\" and \"year\" columns to nullable integers\n",
    "df_weather['month'] = pd.to_numeric(df_weather['month'], errors='coerce')\n",
    "df_weather['year'] = pd.to_numeric(df_weather['year'], errors='coerce')\n",
    "\n",
    "# Set the \"day\" column to 1 for the first day of each month\n",
    "df_weather['day'] = 1\n",
    "\n",
    "# Create the datetime column, keeping NA values\n",
    "df_weather['datetime'] = pd.to_datetime(df_weather[['year', 'month', 'day']], errors='coerce')\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_weather)\n",
    "print(df_weather[df_weather['month'].isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0  year  month  tmax  tmin  af  rain  sun       station  day  \\\n",
      "3540         3540   NaN    NaN   NaN   NaN NaN   NaN  NaN  ballypatrick    1   \n",
      "5023         5023   NaN    NaN   NaN   NaN NaN   NaN  NaN       braemar    1   \n",
      "8908         8908   NaN    NaN   NaN   NaN NaN   NaN  NaN    cwmystwyth    1   \n",
      "9366         9366   NaN    NaN   NaN   NaN NaN   NaN  NaN  dunstaffnage    1   \n",
      "16706       16706   NaN    NaN   NaN   NaN NaN   NaN  NaN     lowestoft    1   \n",
      "17820       17820   NaN    NaN   NaN   NaN NaN   NaN  NaN     lowestoft    1   \n",
      "18745       18745   NaN    NaN   NaN   NaN NaN   NaN  NaN       manston    1   \n",
      "18923       18923   NaN    NaN   NaN   NaN NaN   NaN  NaN         nairn    1   \n",
      "19734       19734   NaN    NaN   NaN   NaN NaN   NaN  NaN         nairn    1   \n",
      "24191       24191   NaN    NaN   NaN   NaN NaN   NaN  NaN       ringway    1   \n",
      "27811       27811   NaN    NaN   NaN   NaN NaN   NaN  NaN   southampton    1   \n",
      "29555       29555   NaN    NaN   NaN   NaN NaN   NaN  NaN   southampton    1   \n",
      "34387       34387   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1   \n",
      "34633       34633   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1   \n",
      "34795       34795   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1   \n",
      "34797       34797   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1   \n",
      "34799       34799   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1   \n",
      "34801       34801   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1   \n",
      "34803       34803   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1   \n",
      "34855       34855   NaN    NaN   NaN   NaN NaN   NaN  NaN        whitby    1   \n",
      "\n",
      "      datetime  \n",
      "3540       NaN  \n",
      "5023       NaN  \n",
      "8908       NaN  \n",
      "9366       NaN  \n",
      "16706      NaN  \n",
      "17820      NaN  \n",
      "18745      NaN  \n",
      "18923      NaN  \n",
      "19734      NaN  \n",
      "24191      NaN  \n",
      "27811      NaN  \n",
      "29555      NaN  \n",
      "34387      NaN  \n",
      "34633      NaN  \n",
      "34795      NaN  \n",
      "34797      NaN  \n",
      "34799      NaN  \n",
      "34801      NaN  \n",
      "34803      NaN  \n",
      "34855      NaN  \n",
      "       Unnamed: 0    year  month  tmax  tmin   af   rain    sun    station  \\\n",
      "0               0  1941.0    1.0   NaN   NaN  NaN   74.7    NaN  aberporth   \n",
      "1               1  1941.0    2.0   NaN   NaN  NaN   69.1    NaN  aberporth   \n",
      "2               2  1941.0    3.0   NaN   NaN  NaN   76.2    NaN  aberporth   \n",
      "3               3  1941.0    4.0   NaN   NaN  NaN   33.7    NaN  aberporth   \n",
      "4               4  1941.0    5.0   NaN   NaN  NaN   51.3    NaN  aberporth   \n",
      "...           ...     ...    ...   ...   ...  ...    ...    ...        ...   \n",
      "37044       37044  2020.0    2.0  10.8   4.5  2.0  117.4   63.1  yeovilton   \n",
      "37045       37045  2020.0    3.0  11.5   3.0  6.0   43.4  159.2  yeovilton   \n",
      "37046       37046  2020.0    4.0  17.5   5.3  3.0   39.8  235.0  yeovilton   \n",
      "37047       37047  2020.0    5.0  19.7   6.8  2.0    3.6  305.6  yeovilton   \n",
      "37048       37048  2020.0    6.0  20.5  11.0  0.0  103.0  187.6  yeovilton   \n",
      "\n",
      "       day    datetime  \n",
      "0        1  1941-01-01  \n",
      "1        1  1941-02-01  \n",
      "2        1  1941-03-01  \n",
      "3        1  1941-04-01  \n",
      "4        1  1941-05-01  \n",
      "...    ...         ...  \n",
      "37044    1  2020-02-01  \n",
      "37045    1  2020-03-01  \n",
      "37046    1  2020-04-01  \n",
      "37047    1  2020-05-01  \n",
      "37048    1  2020-06-01  \n",
      "\n",
      "[37049 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "# Checking the right output\n",
    "df_weather_sol = pd.read_csv('./dataW6/weather_datetime.csv')\n",
    "print(df_weather_sol[df_weather_sol['month'].isna()])\n",
    "print(df_weather_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Write a function *mean_rainfall* that takes in input the dataframe, the name of a weather station, the upper and lower bounds of a time interval and computes the mean *rain* for the time period between (and including) the upper and lower bound. Make the station name not case-sensitive. Use the inputs as in the example below (i.e. upper and lower bounds as strings) (*3 points*)\n",
    "\n",
    "```python \n",
    "mean_rainfall(df_weather, \"Manston\", \"january 2019\", \"march 2020\")  # returns 49.52\n",
    "mean_rainfall(df_weather, \"manston\", \"january 2019\", \"march 2020\")  # also returns 49.52\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.52\n",
      "49.52\n"
     ]
    }
   ],
   "source": [
    "def mean_rainfall(df, station, lower_bound, upper_bound):\n",
    "    station = station.lower()\n",
    "    \n",
    "    lower_bound = datetime.strptime(lower_bound, '%B %Y').date()\n",
    "    upper_bound = datetime.strptime(upper_bound, '%B %Y').date()\n",
    "    lower_bound = np.datetime64(lower_bound)\n",
    "    upper_bound = np.datetime64(upper_bound)\n",
    "    \n",
    "    filtered_df = df[(df['station'] == station) & (df['datetime'] >= lower_bound) & (df['datetime'] <= upper_bound)]\n",
    "    \n",
    "    return filtered_df['rain'].mean()\n",
    "\n",
    "\n",
    "print(mean_rainfall(df_weather, \"Manston\", \"january 2019\", \"march 2020\"))\n",
    "print(mean_rainfall(df_weather, \"manston\", \"january 2019\", \"march 2020\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Expand the function *mean_rainfall* of the previous point, such that it also returns the number of days since the maximum rainfall in the time-period selected and the current date (use 28th of March as reference) (*2 points*)\n",
    "\n",
    "```python \n",
    "mean_rainfall(df_weather, \"Manston\", \"january 2019\", \"march 2020\")  # returns 49.52, 1640\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DatetimeArray' with dtype datetime64[ns] does not support reduction 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[107], line 14\u001b[0m\n\u001b[1;32m      9\u001b[0m     filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m station) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m lower_bound) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m upper_bound)]\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), filtered_df\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_rainfall(df_weather, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mManston\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjanuary 2019\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarch 2020\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(mean_rainfall(df_weather, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmanston\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjanuary 2019\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarch 2020\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[107], line 11\u001b[0m, in \u001b[0;36mmean_rainfall\u001b[0;34m(df, station, lower_bound, upper_bound)\u001b[0m\n\u001b[1;32m      7\u001b[0m upper_bound \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime64(upper_bound)\n\u001b[1;32m      9\u001b[0m filtered_df \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m station) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m lower_bound) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m upper_bound)]\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filtered_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrain\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), filtered_df\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11512\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.sum\u001b[0;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11493\u001b[0m \u001b[38;5;129m@doc\u001b[39m(  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m  11494\u001b[0m     _num_doc,\n\u001b[1;32m  11495\u001b[0m     desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn the sum of the values over the requested axis.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11510\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11511\u001b[0m ):\n\u001b[0;32m> 11512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NDFrame\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28mself\u001b[39m, axis, skipna, numeric_only, min_count, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11280\u001b[0m, in \u001b[0;36mNDFrame.sum\u001b[0;34m(self, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msum\u001b[39m(\n\u001b[1;32m  11273\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  11274\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11278\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  11279\u001b[0m ):\n\u001b[0;32m> 11280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_min_count_stat_function(\n\u001b[1;32m  11281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m, nanops\u001b[38;5;241m.\u001b[39mnansum, axis, skipna, numeric_only, min_count, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m  11282\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:11263\u001b[0m, in \u001b[0;36mNDFrame._min_count_stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, min_count, **kwargs)\u001b[0m\n\u001b[1;32m  11260\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m  11261\u001b[0m     axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stat_axis_number\n\u001b[0;32m> 11263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reduce(\n\u001b[1;32m  11264\u001b[0m     func,\n\u001b[1;32m  11265\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m  11266\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m  11267\u001b[0m     skipna\u001b[38;5;241m=\u001b[39mskipna,\n\u001b[1;32m  11268\u001b[0m     numeric_only\u001b[38;5;241m=\u001b[39mnumeric_only,\n\u001b[1;32m  11269\u001b[0m     min_count\u001b[38;5;241m=\u001b[39mmin_count,\n\u001b[1;32m  11270\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:10519\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m  10515\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m  10517\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[1;32m  10518\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[0;32m> 10519\u001b[0m res \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreduce(blk_func)\n\u001b[1;32m  10520\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor(res)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m  10521\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/managers.py:1534\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m   1532\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1533\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[0;32m-> 1534\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mreduce(func)\n\u001b[1;32m   1535\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[1;32m   1537\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/blocks.py:339\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[1;32m    335\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[1;32m    336\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m--> 339\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    342\u001b[0m         \u001b[38;5;66;03m# TODO(EA2D): special case not needed with 2D EAs\u001b[39;00m\n\u001b[1;32m    343\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[result]])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:10479\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[0;34m(values, axis)\u001b[0m\n\u001b[1;32m  10475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, ExtensionArray):\n\u001b[1;32m  10476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_1d_only_ea_dtype(values\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m  10477\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr, ArrayManager\n\u001b[1;32m  10478\u001b[0m     ):\n\u001b[0;32m> 10479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m  10480\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m values\u001b[38;5;241m.\u001b[39m_reduce(name, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m  10481\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/base.py:1440\u001b[0m, in \u001b[0;36mExtensionArray._reduce\u001b[0;34m(self, name, skipna, **kwargs)\u001b[0m\n\u001b[1;32m   1438\u001b[0m meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meth \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1441\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with dtype \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1442\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not support reduction \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1443\u001b[0m     )\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m meth(skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DatetimeArray' with dtype datetime64[ns] does not support reduction 'sum'"
     ]
    }
   ],
   "source": [
    "def mean_rainfall(df, station, lower_bound, upper_bound):\n",
    "    station = station.lower()\n",
    "    \n",
    "    lower_bound = datetime.strptime(lower_bound, '%B %Y').date()\n",
    "    upper_bound = datetime.strptime(upper_bound, '%B %Y').date()\n",
    "    lower_bound = np.datetime64(lower_bound)\n",
    "    upper_bound = np.datetime64(upper_bound)\n",
    "    date_today = \n",
    "    \n",
    "    filtered_df = df[(df['station'] == station) & (df['datetime'] >= lower_bound) & (df['datetime'] <= upper_bound)]\n",
    "    \n",
    "    return filtered_df['rain'].mean(), filtered_df.sum()\n",
    "\n",
    "\n",
    "print(mean_rainfall(df_weather, \"Manston\", \"january 2019\", \"march 2020\"))\n",
    "print(mean_rainfall(df_weather, \"manston\", \"january 2019\", \"march 2020\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
